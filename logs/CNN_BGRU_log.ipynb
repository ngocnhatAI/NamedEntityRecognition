{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hquan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.3920\n",
      "Train Precision: 0.8186, Recall: 0.7794, F1: 0.7922\n",
      "Dev Precision: 0.8182, Recall: 0.7669, F1: 0.7871\n",
      "\n",
      "Epoch 2/10, Loss: 0.2080\n",
      "Train Precision: 0.8297, Recall: 0.8303, F1: 0.8239\n",
      "Dev Precision: 0.8283, Recall: 0.8193, F1: 0.8176\n",
      "\n",
      "Epoch 3/10, Loss: 0.1551\n",
      "Train Precision: 0.8371, Recall: 0.8676, F1: 0.8506\n",
      "Dev Precision: 0.8355, Recall: 0.8509, F1: 0.8419\n",
      "\n",
      "Epoch 4/10, Loss: 0.1218\n",
      "Train Precision: 0.8313, Recall: 0.8800, F1: 0.8521\n",
      "Dev Precision: 0.8236, Recall: 0.8618, F1: 0.8396\n",
      "\n",
      "Epoch 5/10, Loss: 0.0994\n",
      "Train Precision: 0.8869, Recall: 0.8922, F1: 0.8881\n",
      "Dev Precision: 0.8716, Recall: 0.8695, F1: 0.8690\n",
      "\n",
      "Epoch 6/10, Loss: 0.0848\n",
      "Train Precision: 0.9126, Recall: 0.9052, F1: 0.9075\n",
      "Dev Precision: 0.8883, Recall: 0.8745, F1: 0.8801\n",
      "\n",
      "Epoch 7/10, Loss: 0.0741\n",
      "Train Precision: 0.9152, Recall: 0.9161, F1: 0.9144\n",
      "Dev Precision: 0.8863, Recall: 0.8842, F1: 0.8840\n",
      "\n",
      "Epoch 8/10, Loss: 0.0665\n",
      "Train Precision: 0.9305, Recall: 0.9255, F1: 0.9270\n",
      "Dev Precision: 0.8960, Recall: 0.8866, F1: 0.8902\n",
      "\n",
      "Epoch 9/10, Loss: 0.0602\n",
      "Train Precision: 0.9366, Recall: 0.9348, F1: 0.9352\n",
      "Dev Precision: 0.9035, Recall: 0.8905, F1: 0.8958\n",
      "\n",
      "Epoch 10/10, Loss: 0.0563\n",
      "Train Precision: 0.9359, Recall: 0.9296, F1: 0.9303\n",
      "Dev Precision: 0.8932, Recall: 0.8871, F1: 0.8864\n",
      "\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "# Chuyển mô hình sang device (GPU hoặc CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "vocab_size=wordEmbeddings.shape[0] \n",
    "word_emb_dim=wordEmbeddings.shape[1] \n",
    "word_embeddings=wordEmbeddings\n",
    "case_emb_dim=len(case2Idx)\n",
    "case_embeddings=caseEmbeddings \n",
    "char_size=len(char2Idx)\n",
    "char_emb_dim=30\n",
    "conv_out_channels=30\n",
    "conv_kernel_size=3\n",
    "gru_hidden_size=200 \n",
    "num_labels=len(label2Idx)\n",
    "dropout=0.5\n",
    "dropout_recurrent=0.2\n",
    "\n",
    "# Khởi tạo mô hình (sử dụng dữ liệu embedding đã cho)\n",
    "model = CNN_BGRU(\n",
    "    vocab_size=vocab_size, \n",
    "    word_emb_dim=word_emb_dim, \n",
    "    word_embeddings=word_embeddings, \n",
    "    case_emb_dim=case_emb_dim,\n",
    "    case_embeddings=case_embeddings, \n",
    "    char_size=char_size, \n",
    "    char_emb_dim=char_emb_dim, \n",
    "    conv_out_channels=conv_out_channels, \n",
    "    conv_kernel_size=conv_kernel_size, \n",
    "    gru_hidden_size=gru_hidden_size, \n",
    "    num_labels=num_labels,\n",
    "    dropout=dropout, \n",
    "    dropout_recurrent=dropout_recurrent,\n",
    "    device=device\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# Khởi tạo Optimizer và Loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()  # Loss cho classification\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "train_model(model, train_loaders, dev_loaders, optimizer, criterion, epochs=10)\n",
    "# train_model_baseline(model, train_loaders, dev_loaders, optimizer, criterion, epochs=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-14T12:28:50.292836Z",
     "iopub.status.idle": "2024-12-14T12:28:50.293278Z",
     "shell.execute_reply": "2024-12-14T12:28:50.293076Z",
     "shell.execute_reply.started": "2024-12-14T12:28:50.293037Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.91      0.93      0.92      1668\n",
      "      B-MISC       0.84      0.76      0.80       702\n",
      "       B-ORG       0.83      0.89      0.86      1661\n",
      "       B-PER       0.93      0.95      0.94      1617\n",
      "       I-LOC       0.80      0.82      0.81       257\n",
      "      I-MISC       0.56      0.61      0.58       216\n",
      "       I-ORG       0.70      0.90      0.79       835\n",
      "       I-PER       0.95      0.99      0.97      1156\n",
      "           O       1.00      0.99      0.99     38323\n",
      "\n",
      "    accuracy                           0.97     46435\n",
      "   macro avg       0.84      0.87      0.85     46435\n",
      "weighted avg       0.97      0.97      0.97     46435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "    \n",
    "with torch.no_grad():\n",
    "    for loader in test_loaders:\n",
    "        for batch in loader:\n",
    "            tokens, cases, chars, labels = batch\n",
    "            tokens = tokens.to(model.device)\n",
    "            cases  = cases.to(model.device)\n",
    "            chars  = chars.to(model.device)\n",
    "            labels = labels.to(model.device)\n",
    "                \n",
    "            outputs = model.forward(tokens, cases, chars)  # [batch_size, seq_len, num_labels]\n",
    "            preds = torch.argmax(outputs, dim=-1)  # [batch_size, seq_len]\n",
    "                \n",
    "            all_preds.extend(preds.cpu().numpy().tolist())\n",
    "            all_labels.extend(labels.cpu().numpy().tolist())\n",
    "    \n",
    "y_pred = []\n",
    "y_true = []\n",
    "for pred_seq, true_seq in zip(all_preds, all_labels):\n",
    "    for p, t in zip(pred_seq, true_seq):\n",
    "            y_pred.append(p)\n",
    "            y_true.append(t)\n",
    "labels = list(label2Idx.values())\n",
    "target_names = list(label2Idx.keys())\n",
    "report = classification_report(y_true, y_pred, labels=labels, target_names=target_names, zero_division=0)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6296502,
     "sourceId": 10191035,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
